{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries and APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import textwrap\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import OpenAI\n",
    "from langchain_core.prompts import PromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate, ChatPromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents import AgentType\n",
    "from langchain.agents import load_tools\n",
    "from langchain.agents import get_all_tool_names\n",
    "\n",
    "from langchain_community.embeddings import OpenAIEmbeddings\n",
    "from langchain.document_loaders import YoutubeLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load API Keys from .env File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declaring useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Input: The Youtube Video URL\n",
    "### Output: A vector Store based on the transcripts of the input youtube video\n",
    "\n",
    "def create_db_from_youtube_video_url(video_url):\n",
    "    ##Loading Youtube Transcripts as documents\n",
    "    loader = YoutubeLoader.from_youtube_url(video_url)\n",
    "    transcript = loader.load()\n",
    "    \n",
    "    ##Splitting the documents into chunks, with a chunk_size and overlap strategy\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap =100)\n",
    "    docs = text_splitter.split_documents(transcript)\n",
    "    \n",
    "    ## Creating a Vector store client based on th documents and chuks\n",
    "    db = FAISS.from_documents(docs, embeddings)\n",
    "    \n",
    "    return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Input: The vector store created in the last step, Query(Input) and k (number of closest embeddings to Query)\n",
    "### Output: Response to the Query, k closest docs joined together(for model transparency and Understanding)\n",
    "\n",
    "def get_response_from_query(db, query, k=4):\n",
    "    \n",
    "    ## Finding the k closest vector embeddings to the query in the VS\n",
    "    docs = db.similarity_search(query, k)\n",
    "    docs_page_content = \" \".join([d.page_content for d in docs])\n",
    "    \n",
    "    \n",
    "    ## Initializing a ChatModel \n",
    "    chat = ChatOpenAI(\n",
    "        model = \"gpt-3.5-turbo\"\n",
    "        ,api_key=\"sk-None-NmK2oXjPHTSresy9n630T3BlbkFJHXNgwZkFNRNVfUIX75lN\"\n",
    "        ,temperature=0.2\n",
    "    )\n",
    "    chunks = []\n",
    "    \n",
    "    ##Initializing a template\n",
    "    template = \"\"\"\n",
    "                You are a helpful assistant that can answer questions about the youtube videos based on the video's transcript: {docs}\n",
    "                \n",
    "                Only use the factual information from the transcript to answer the question.\n",
    "                \n",
    "                If you feel like you don't have enough information to answer the question, say 'I don't know'\n",
    "                \n",
    "                Your answers should be verbosed and detailed.\n",
    "                \"\"\"\n",
    "    ## Initializing system prompt\n",
    "    system_message_prompt = SystemMessagePromptTemplate.from_template(template)\n",
    "    \n",
    "    \n",
    "    ## Initializing Human prompt\n",
    "    human_template = \"Answer the following question {question}\"\n",
    "    human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "    \n",
    "    ## Creating a chatpromot based on Human and System prompt\n",
    "    chat_prompt = ChatPromptTemplate.from_messages(\n",
    "                [system_message_prompt, human_message_prompt])\n",
    "    \n",
    "    ## Chaining everything\n",
    "    chain = LLMChain(llm=chat, prompt=chat_prompt)\n",
    "    \n",
    "    ## Getting the response to the query\n",
    "    response = chain.run(question= query, docs= docs_page_content)\n",
    "    response = response.replace(\"\\n\",\"\")\n",
    "       \n",
    "    \n",
    "    return response, docs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_up(video_url):\n",
    "    db = create_db_from_youtube_video_url\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sam Altman: OpenAI, GPT-5, Sora, Board Saga, Elon Musk, Ilya, Power & AGI | Lex Fridman Podcast \n",
    "video_url = \"https://www.youtube.com/watch?v=jvqFAi7vkBc\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The video features a conversation between Sam Altman and the host. They discuss the\n",
      "importance of incentivizing journalistic efforts that prioritize in-depth journalism\n",
      "and balanced representation of news. They touch on the issue of sensationalism in\n",
      "media and express a desire to see more celebration and positivity in society. The\n",
      "conversation also delves into advancements in AI models like DALLÂ·E and Sora,\n",
      "highlighting the progress in modeling physics and image generation. The discussion\n",
      "ends with a contemplation on the existence of alien civilizations.\n"
     ]
    }
   ],
   "source": [
    "db = create_db_from_youtube_video_url(video_url)\n",
    "\n",
    "query = \"Give me a short summary of the video\"\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "response, docs = get_response_from_query(db, query)\n",
    "\n",
    "print(textwrap.fill(response, width=85))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "### End"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
