{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries and APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import textwrap\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import OpenAI\n",
    "from langchain_core.prompts import PromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate, ChatPromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "import openai\n",
    "\n",
    "\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents import AgentType\n",
    "from langchain.agents import load_tools\n",
    "from langchain.agents import get_all_tool_names\n",
    "\n",
    "from langchain_community.embeddings import OpenAIEmbeddings\n",
    "from langchain.document_loaders import YoutubeLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.chains.conversation.memory import ConversationBufferWindowMemory\n",
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load API Keys from .env File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_dotenv(find_dotenv())\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declaring useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sam Altman: OpenAI, GPT-5, Sora, Board Saga, Elon Musk, Ilya, Power & AGI | Lex Fridman Podcast \n",
    "video_url = \"https://www.youtube.com/watch?v=jvqFAi7vkBc\" \n",
    "business_tax_url = \"https://www.youtube.com/watch?v=tQoVfGUH--o\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Input: The Youtube Video URL\n",
    "### Output: A vector Store based on the transcripts of the input youtube video\n",
    "\n",
    "def create_db_from_youtube_video_url(video_url):\n",
    "    ##Loading Youtube Transcripts as documents\n",
    "    loader = YoutubeLoader.from_youtube_url(video_url)\n",
    "    transcript = loader.load()\n",
    "    \n",
    "    ##Splitting the documents into chunks, with a chunk_size and overlap strategy\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap =100)\n",
    "    docs = text_splitter.split_documents(transcript)\n",
    "    \n",
    "    ## Creating a Vector store client based on th documents and chuks\n",
    "    db = FAISS.from_documents(docs, embeddings)\n",
    "    \n",
    "    return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_test = create_db_from_youtube_video_url(business_tax_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"why should i incorporate?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* I want to get clear because I feel like a lot of people get really excited about this and get a little confused about how it works I cannot claim 100 of these uh expenses as tax deductions only a percentage so I can only claim a certain percentage of my home that I use for business purposes only another thing I also want to share too if you do not own your home you can claim your rent so even if you're renting you can claim that as a tax deduction as well and next we've got professional fees now if you watch my recent video about um a sole proprietorship versus Corporation and I shared my experience of being a sole proprietor for about five and a half years and a year ago incorporating my business the one thing I shared is I'm spending a lot more money on professional fees now that I'm Incorporated the good thing is those fee and I'm talking about you know legal fees accounting fees and Consulting fees um you can write those off so that is one kind of nice Silver Lining so if you you [Score: {'source': 'tQoVfGUH--o'}] *\n",
      "* Microsoft Office I also pay for that gosh there's a lot of them that I use here actually so you can make an account try it out yourself take a look at some of these recommendations for write-offs and see some of their deals and you know start taking advantage and trying to lower your taxable income well I hope you found this video helpful but honestly I cannot stress this enough if you run your own small incorporated business like I do myself the best investment I ever made was accounting software my bookkeeper and my accountant so if you are running a Canadian Corporation and you need some help definitely check out reinvest wealth and also their new tax write-off recommendation engine you can find all that information and test it out yourself at reinvestwealth.com honestly it took me like two seconds to create an account and like I mentioned at the beginning of this video their base uh software for accounting is absolutely free so to cap things off if you have any questions uh [Score: {'source': 'tQoVfGUH--o'}] *\n",
      "* one of the best parts about running a small business aside from obviously being your own boss which is awesome is the write-offs but if you're a very new small business or maybe you aren't like me he's been doing it for a little while but you've realized there's only a few months left in the year and yeah you need some more tax deductions ASAP well you've come to the right place in this video I'm going to share the top 10 tax write-offs for Canadian small businesses that you should absolutely know about hey my name is Jessica Morehouse and this channel is about all things money so if you want to continue to expand your knowledge and learn about entrepreneurship and taxes but also personal finance and investing and everything in between make sure to subscribe to my channel and hit that notification Bell so you are notified the next time I have a brand new video now before we Dive Right In because there's quite a bit to get into a big thank you to reinvest wealth for sponsoring this [Score: {'source': 'tQoVfGUH--o'}] *\n",
      "* had to incur that cost in order for you to generate income for your business as an example that I share often um I you know one of the things I do in my business is public speaking and often it is on the other side of town or someplace not close and uh if that's the case I'm probably honestly not going to take transit because I don't want to like ruin my hair makeup or anything like that so I'll probably take a taxi or an Uber and so I uh pay for that and then I save those receipts and then I claim them on my taxes because it does qualify as a travel business expense because guess what I needed to take that Uber or taxi in order to be at that speaking game in order to get paid another write-off that you may be able to claim are professional dues so I am an accredited financial counselor Canada in order for me to continue every single year to to use that designation I have to pay an annual fee to an organization luckily it is a write-off so I get to claim that on my taxes another [Score: {'source': 'tQoVfGUH--o'}] *\n",
      "* thousand dollars from the one hundred thousand dollars you earned to get to eighty thousand dollars eighty thousand dollars is the amount that you would have to pay taxes on not the original one hundred thousand dollars the logic is the more tax deductions you claim the low your taxable income becomes and subsequently the lower your tax bill to the CRA becomes as well one more thing because I see this all the time especially my comments or online especially with uh new small businesses not all business expenses qualify as write-offs a qualifying business expense needs to be seen Through The Eyes of the CRA as an expense that you incurred because you needed to either continue to operate your business or to generate income for your business so it's really important for you to know before you spend any money whether an expense is actually a write-off or does not qualify because if it doesn't qualify you spent the money and you don't get that tax benefit now if you want to learn a little [Score: {'source': 'tQoVfGUH--o'}] *\n"
     ]
    }
   ],
   "source": [
    "results = db_test.similarity_search(\n",
    "    query,\n",
    "    k=5\n",
    ")\n",
    "for res in results:\n",
    "    print(f'* {res.page_content} [Score: {res.metadata}] *')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initializing a ChatModel \n",
    "llm = ChatOpenAI(\n",
    "    model = \"gpt-3.5-turbo\"\n",
    "    ,api_key=openai_api_key\n",
    "    ,temperature=0.2\n",
    "    )\n",
    "    \n",
    "#Conversation Memory\n",
    "conversational_memory = ConversationBufferMemory(\n",
    "    memory_key = \"chat_history\",\n",
    "    k=5,\n",
    "    return_messages=True\n",
    "    )\n",
    "# retrieval qa Chain\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=db_test.as_retriever(),\n",
    "    return_source_documents=True,\n",
    "    memory = conversational_memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# qa.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import Tool\n",
    "\n",
    "tools =[\n",
    "    Tool(\n",
    "        name= \"knowledge base\",\n",
    "        func=qa.run,\n",
    "        description=(\n",
    "            'use this tool for every query to get more information and stories on the topic'\n",
    "        )\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/karankaran/Desktop/Github_Karan/Youtube_Questioning_ChatBot/venv/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:151: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 1.0. Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import initialize_agent\n",
    "\n",
    "agent = initialize_agent(\n",
    "    agent = 'chat-conversational-react-description',\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    verbose=True\n",
    "    ,memory = conversational_memory,\n",
    "    max_iterations=3,\n",
    "    early_stopping_method=\"generate\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['agent_scratchpad', 'chat_history', 'input'], input_types={'chat_history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]], 'agent_scratchpad': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='Assistant is a large language model trained by OpenAI.\\n\\nAssistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\\n\\nAssistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\\n\\nOverall, Assistant is a powerful system that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist.')), MessagesPlaceholder(variable_name='chat_history'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='TOOLS\\n------\\nAssistant can ask the user to use tools to look up information that may be helpful in answering the users original question. The tools the human can use are:\\n\\n> knowledge base: use this tool for every query to get more information and stories on the topic\\n\\nRESPONSE FORMAT INSTRUCTIONS\\n----------------------------\\n\\nWhen responding to me, please output a response in one of two formats:\\n\\n**Option 1:**\\nUse this if you want the human to use a tool.\\nMarkdown code snippet formatted in the following schema:\\n\\n```json\\n{{\\n    \"action\": string, \\\\\\\\ The action to take. Must be one of knowledge base\\n    \"action_input\": string \\\\\\\\ The input to the action\\n}}\\n```\\n\\n**Option #2:**\\nUse this if you want to respond directly to the human. Markdown code snippet formatted in the following schema:\\n\\n```json\\n{{\\n    \"action\": \"Final Answer\",\\n    \"action_input\": string \\\\\\\\ You should put what you want to return to use here\\n}}\\n```\\n\\nUSER\\'S INPUT\\n--------------------\\nHere is the user\\'s input (remember to respond with a markdown code snippet of a json blob with a single action, and NOTHING else):\\n\\n{input}')), MessagesPlaceholder(variable_name='agent_scratchpad')])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.agent.llm_chain.prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_msg = \"\"\"You are a helpful assistant that can answer questions about the youtube videos based on the video's transcript: {docs}\n",
    "                \n",
    "                Only use the factual information from the transcript to answer the question.\n",
    "                \n",
    "                If you feel like you don't have enough information to answer the question, say 'I don't know'\n",
    "                \n",
    "                Your answers should be verbosed and detailed.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt =agent.agent.create_prompt(\n",
    "    system_message=sys_msg,\n",
    "    tools=tools\n",
    ")\n",
    "agent.agent.llm_chain.prompt = prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['agent_scratchpad', 'chat_history', 'input'], input_types={'chat_history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]], 'agent_scratchpad': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template=\"You are a helpful assistant that can answer questions about the youtube videos based on the video's transcript:\\n                \\n                Only use the factual information from the transcript to answer the question.\\n                \\n                If you feel like you don't have enough information to answer the question, say 'I don't know'\\n                \\n                Your answers should be verbosed and detailed.\\n\")), MessagesPlaceholder(variable_name='chat_history'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='TOOLS\\n------\\nAssistant can ask the user to use tools to look up information that may be helpful in answering the users original question. The tools the human can use are:\\n\\n> knowledge base: use this tool for every query to get more information and stories on the topic\\n\\nRESPONSE FORMAT INSTRUCTIONS\\n----------------------------\\n\\nWhen responding to me, please output a response in one of two formats:\\n\\n**Option 1:**\\nUse this if you want the human to use a tool.\\nMarkdown code snippet formatted in the following schema:\\n\\n```json\\n{{\\n    \"action\": string, \\\\\\\\ The action to take. Must be one of knowledge base\\n    \"action_input\": string \\\\\\\\ The input to the action\\n}}\\n```\\n\\n**Option #2:**\\nUse this if you want to respond directly to the human. Markdown code snippet formatted in the following schema:\\n\\n```json\\n{{\\n    \"action\": \"Final Answer\",\\n    \"action_input\": string \\\\\\\\ You should put what you want to return to use here\\n}}\\n```\\n\\nUSER\\'S INPUT\\n--------------------\\nHere is the user\\'s input (remember to respond with a markdown code snippet of a json blob with a single action, and NOTHING else):\\n\\n{input}')), MessagesPlaceholder(variable_name='agent_scratchpad')])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.agent.llm_chain.prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": \"I am an assistant here to help answer questions based on the transcript of YouTube videos.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Tell me about yourself',\n",
       " 'chat_history': [HumanMessage(content='Tell me about yourself'),\n",
       "  AIMessage(content='I am an assistant here to help answer questions based on the transcript of YouTube videos.')],\n",
       " 'output': 'I am an assistant here to help answer questions based on the transcript of YouTube videos.'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "agent(\"Tell me about yourself\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": \"I am here to help answer questions based on the transcript of YouTube videos.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'what can you help me with?',\n",
       " 'chat_history': [HumanMessage(content='Tell me about yourself'),\n",
       "  AIMessage(content='I am an assistant here to help answer questions based on the transcript of YouTube videos.'),\n",
       "  HumanMessage(content='what can you help me with?'),\n",
       "  AIMessage(content='I am here to help answer questions based on the transcript of YouTube videos.')],\n",
       " 'output': 'I am here to help answer questions based on the transcript of YouTube videos.'}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent(\"what can you help me with?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": \"I am an AI assistant programmed to assist with answering questions based on the transcript of YouTube videos.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'are you alive?',\n",
       " 'chat_history': [HumanMessage(content='Tell me about yourself'),\n",
       "  AIMessage(content='I am an assistant here to help answer questions based on the transcript of YouTube videos.'),\n",
       "  HumanMessage(content='what can you help me with?'),\n",
       "  AIMessage(content='I am here to help answer questions based on the transcript of YouTube videos.'),\n",
       "  HumanMessage(content='are you alive?'),\n",
       "  AIMessage(content='I am an AI assistant programmed to assist with answering questions based on the transcript of YouTube videos.')],\n",
       " 'output': 'I am an AI assistant programmed to assist with answering questions based on the transcript of YouTube videos.'}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent(\"are you alive?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Input: The vector store created in the last step, Query(Input) and k (number of closest embeddings to Query)\n",
    "### Output: Response to the Query, k closest docs joined together(for model transparency and Understanding)\n",
    "\n",
    "def get_response_from_query(db, query, k=4):\n",
    "    \n",
    "    ## Finding the k closest vector embeddings to the query in the VS\n",
    "    docs = db.similarity_search(query, k)\n",
    "    docs_page_content = \" \".join([d.page_content for d in docs])\n",
    "    \n",
    "    \n",
    "    ## Initializing a ChatModel \n",
    "    chat = ChatOpenAI(\n",
    "        model = \"gpt-3.5-turbo\"\n",
    "        ,api_key=openai_api_key\n",
    "        ,temperature=0.2\n",
    "    )\n",
    "    \n",
    "    #Conversation Memory\n",
    "    conversational_memory = ConversationBufferMemory(\n",
    "        memory_key = \"chat_history\",\n",
    "        k=5,\n",
    "        return_messages=True\n",
    "    )\n",
    "\n",
    "    #Retrival qa Chain\n",
    "    qa = RetrievalQA.from_chain_type(\n",
    "        llm=chat,\n",
    "        chain_type=\"stuff\",\n",
    "        retriever=db.as_retriever(),\n",
    "        return_source_documents=True,\n",
    "        memory = conversational_memory\n",
    "    )\n",
    "    \n",
    "    ##Initializing a template\n",
    "    template = \"\"\"\n",
    "                You are a helpful assistant that can answer questions about the youtube videos based on the video's transcript: {docs}\n",
    "                \n",
    "                Only use the factual information from the transcript to answer the question.\n",
    "                \n",
    "                If you feel like you don't have enough information to answer the question, say 'I don't know'\n",
    "                \n",
    "                Your answers should be verbosed and detailed.\n",
    "                \"\"\"\n",
    "    ## Initializing system prompt\n",
    "    system_message_prompt = SystemMessagePromptTemplate.from_template(template)\n",
    "    \n",
    "    \n",
    "    ## Initializing Human prompt\n",
    "    human_template = \"Answer the following question {question}\"\n",
    "    human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "    \n",
    "    ## Creating a chatpromot based on Human and System prompt\n",
    "    chat_prompt = ChatPromptTemplate.from_messages(\n",
    "                [system_message_prompt, human_message_prompt])\n",
    "    \n",
    "    ## Chaining everything\n",
    "    chain = LLMChain(llm=chat, prompt=chat_prompt)\n",
    "\n",
    "    \n",
    "    ## Getting the response to the query\n",
    "    response = chain.run(question= query, docs= docs_page_content)\n",
    "    response = response.replace(\"\\n\",\"\")\n",
    "       \n",
    "    \n",
    "    return response, docs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_up(video_url):\n",
    "    db = create_db_from_youtube_video_url\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = create_db_from_youtube_video_url(business_tax_url)\n",
    "\n",
    "query = \"Give me a short summary of the video\"\n",
    "    \n",
    "response, docs = get_response_from_query(db, query)\n",
    "\n",
    "print(textwrap.fill(response, width=85))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue the conversation with memory\n",
    "follow_up_query = \"What are the main points discussed?\"\n",
    "follow_up_response, _ = get_response_from_query(db, follow_up_query)\n",
    "print(textwrap.fill(follow_up_response, width=85))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### End"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
